{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d940b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88dc5d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated GPU Memory: 0.00 GB\n",
      "Cached GPU Memory: 0.00 GB\n",
      "Compiling\n",
      "Done compiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - For input x.1, found user specified input dtype as Float. The compiler is going to use the user setting Float\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import collections as coll\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def print_gpu_memory():\n",
    "    allocated_memory = torch.cuda.memory_allocated() / 1024 ** 3\n",
    "    cached_memory = torch.cuda.memory_reserved() / 1024 ** 3\n",
    "    print(f\"Allocated GPU Memory: {allocated_memory:.2f} GB\")\n",
    "    print(f\"Cached GPU Memory: {cached_memory:.2f} GB\")\n",
    "\n",
    "print_gpu_memory()\n",
    "import time as TIME\n",
    "import torch_tensorrt\n",
    "\n",
    "from FHNCUDAlib import FHNCUDA\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "loaded_module = nn.Linear(10,10)\n",
    "#loaded_module.load_state_dict()\n",
    "\n",
    "#print(loaded_module.state_dict())\n",
    "st=torch.load('network.0.pth')\n",
    "#print(st)\n",
    "\n",
    "\n",
    "pt.set_grad_enabled (False) \n",
    "numinputs=1\n",
    "numoutputs=2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, numinputs, numoutputs, numlayers=4, H=10):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.utils.weight_norm(nn.Linear(numinputs, H), name='weight', dim=0).cuda())\n",
    "\n",
    "        for _ in range(numlayers - 1):\n",
    "            self.layers.append(nn.utils.weight_norm(nn.Linear(H, H), name='weight', dim=0).cuda())\n",
    "\n",
    "        self.final_layer = nn.Linear(H, numoutputs).cuda()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            layer.eval()\n",
    "        self.final_layer.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = f.silu(layer(x))\n",
    "\n",
    "        return self.final_layer(x)\n",
    "\n",
    "    def load(self, od):\n",
    "        for k, v in od.items():\n",
    "            if k.startswith('_impl.layers'):\n",
    "                layer_num = int(k.split('.')[2])\n",
    "                layer = self.layers[layer_num]\n",
    "                if k.endswith('linear.weight'):\n",
    "                    layer.weight_v.data = v\n",
    "                    layer.weight_v.requires_grad = False\n",
    "                elif k.endswith('linear.weight_g'):\n",
    "                    layer.weight_g.data = v\n",
    "                    layer.weight_g.requires_grad = False\n",
    "                elif k.endswith('linear.bias'):\n",
    "                    layer.bias.data = v\n",
    "                    layer.bias.requires_grad = False\n",
    "            elif k == '_impl.final_layer.linear.weight':\n",
    "                self.final_layer.weight.data = v\n",
    "                self.final_layer.weight.requires_grad = False\n",
    "            elif k == '_impl.final_layer.linear.bias':\n",
    "                self.final_layer.bias.data = v\n",
    "                self.final_layer.bias.requires_grad = False\n",
    "\n",
    "    def __prepare_scriptable__(self):\n",
    "        for layer in self.layers:\n",
    "            for hook in layer._forward_pre_hooks.values():\n",
    "                if hook.__module__ == \"torch.nn.utils.weight_norm\" and hook.__class__.__name__ == \"WeightNorm\":\n",
    "                    torch.nn.utils.remove_weight_norm(layer)\n",
    "        return self\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def Modelrun_s(x,M):\n",
    "   \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    my2dspace = pt.tensor(x, requires_grad=False).float().cuda()\n",
    "    M.eval()\n",
    "    start_time = TIME.time()\n",
    "    myOutput = M(my2dspace)\n",
    "    reftime = TIME.time()- start_time\n",
    " \n",
    "    myCPUOutput = myOutput.cpu()\n",
    "\n",
    "\n",
    "    uu = myCPUOutput.numpy()\n",
    "\n",
    "    #print('uu: ', uu.T[0])\n",
    "\n",
    "    myCPUOutput.squeeze().detach().numpy()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return uu,reftime\n",
    "\n",
    "\n",
    "def Modelrun(x, M, batch_size=10*20*10*200):\n",
    "\n",
    "    my2dspace = x\n",
    "    M.eval()\n",
    "        \n",
    "    num_samples = my2dspace.shape[0]\n",
    "  \n",
    "\n",
    "    uu_list = []\n",
    "   \n",
    "\n",
    "    reftime =0\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_input =torch.tensor(my2dspace[i:i+batch_size], requires_grad=False).float().cuda() \n",
    "        start_time = TIME.time()\n",
    "        batch_output = M(batch_input)\n",
    "        reftime =reftime+ TIME.time() - start_time\n",
    "        uu_list.append(batch_output.cpu().numpy())\n",
    "        del batch_input\n",
    "        del batch_output\n",
    "        print_gpu_memory()\n",
    "       \n",
    " \n",
    "    uu = np.concatenate(uu_list)\n",
    "    \n",
    "    print_gpu_memory()\n",
    "    return uu, reftime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compileRT(modelTorch=Net(2,2)):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    X=np.zeros((2,5))\n",
    "    model = torch.jit.script(modelTorch).eval()  # torch module needs to be in eval (not training) mode\n",
    "\n",
    "\n",
    "\n",
    "    trt_ts_module = torch_tensorrt.compile(modelTorch, inputs = [torch_tensorrt.Input(\n",
    "            min_shape=(1,4),\n",
    "            opt_shape=(5000,4),\n",
    "            max_shape=(20000*26,4),\n",
    "            dtype=torch.float32)],\n",
    "        enabled_precisions = torch.float32, # Run with FP32\n",
    "        workspace_size = 1 << 33\n",
    "    )\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return trt_ts_module\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Compiling\")\n",
    "net =Net(4,2,10,10)\n",
    "\n",
    "PATH=\"\"\n",
    "od=pt.load('network.0.pth')\n",
    "net.load(od)\n",
    "net=net.cuda()\n",
    "\n",
    "\n",
    "model =  compileRT(net)\n",
    "print(\"Done compiling\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e226fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cuda.cu -o a.out  ##Estava seguindo o tutorioal do torch rt tentando encontrar uma forma de converter, tentei remover os pesos para entÃ£o converte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b63e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated GPU Memory: 0.00 GB\n",
      "Cached GPU Memory: 0.00 GB\n",
      "6\n",
      "Number of rows in the CSV file:  200000 13\n",
      "-------------------------CUDA ----------------------------\n",
      "6\n",
      "Number of rows in the CSV file:  200000 13\n",
      "Shape cudapred  (2600000,)\n",
      "cuda time [0.000562304, 0.035071327, 0.467486145]\n",
      "Error Calculation\n",
      "mean nan\n",
      "max nan\n",
      "-------------------------TORCH ----------------------------\n",
      "(13,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(t))\n\u001b[1;32m     62\u001b[0m start_time \u001b[38;5;241m=\u001b[39m TIME\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 63\u001b[0m u,net_time\u001b[38;5;241m=\u001b[39m\u001b[43mModelrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m u_net\u001b[38;5;241m=\u001b[39mu\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape netpred \u001b[39m\u001b[38;5;124m\"\u001b[39m,np\u001b[38;5;241m.\u001b[39mshape(u_net))\n",
      "Cell \u001b[0;32mIn[9], line 122\u001b[0m, in \u001b[0;36mModelrun\u001b[0;34m(x, M, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mModelrun\u001b[39m(x, M, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m    121\u001b[0m     my2dspace \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m    124\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m my2dspace\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    127\u001b[0m     uu_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print_gpu_memory()\n",
    "from itertools import product\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "krange = [(0.08 + 0.03 * i * 0.1) for i in range(0, 100)]\n",
    "vrange = [(0.004 + 0.1 * i * 0.12) for i in range(0, 20)]\n",
    "urange = [(0.005 + 0.1 * i * 1) for i in range(0, 100)]\n",
    "\n",
    "\n",
    "param_list = np.array(list(product(urange,vrange, krange )))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x0=np.array(param_list)\n",
    "dt,tt=0.0001,5\n",
    "\n",
    "rate=4000\n",
    "\n",
    "\n",
    "##Cuda ref\n",
    "start_time = TIME.time()\n",
    "u,v ,t,p=FHNCUDA.run(x0,tt,dt,rate)\n",
    "reftime = TIME.time()- start_time\n",
    "p=[i/1000 for i in p[0]]\n",
    "u_ref=np.array(u).flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"-------------------------CUDA ----------------------------\")\n",
    "\n",
    "###Cuda run\n",
    "start_time = TIME.time()\n",
    "u,v ,t,p=FHNCUDA.run(x0,tt,dt*100,rate/100)\n",
    "cudatime = TIME.time()- start_time\n",
    "u_num=np.array(u).flatten()\n",
    "#print(np.unique(t))\n",
    "p=[i/1000 for i in p[0]]\n",
    "print(\"Shape cudapred \",np.shape(u_num))\n",
    "print(\"cuda time\",p)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_num)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "x0 = [item for sublist in x0 for item in sublist]\n",
    "t = [item for sublist in t for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##PRED NETWORK TORCH\n",
    "print(\"-------------------------TORCH ----------------------------\")\n",
    "print(np.shape(t))\n",
    "start_time = TIME.time()\n",
    "u,net_time=Modelrun(x0,t[1:],net)\n",
    "\n",
    "u_net=u.T[0].flatten()\n",
    "\n",
    "print(\"Shape netpred \",np.shape(u_net))\n",
    "print(\"net time\", net_time)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_net)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "\n",
    "\n",
    "plt.plot(u_ref,\"b\")\n",
    "plt.plot(u_net,\"r\")\n",
    "\n",
    "plt.show()\n",
    "(\"-----------------------------------------------------\")\n",
    "#PRED NETWORK JIT\n",
    "print(\"-------------------------JIT ----------------------------\")\n",
    "\n",
    "print(np.shape(t))\n",
    "start_time = TIME.time()\n",
    "u,net_time=Modelrun(x0,t[1:],torch.jit.script(net).cuda())\n",
    "u_net=u.T[0].flatten()\n",
    "print(\"Shape netpred \",np.shape(u_net))\n",
    "print(\"net time\", net_time)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_net)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "\n",
    "\n",
    "plt.plot(u_ref,\"b\")\n",
    "plt.plot(u_net,\"r\")\n",
    "plt.show()\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "##PRED NETWORK RT\n",
    "print(\"-------------------------TENSOR RT ----------------------------\")\n",
    "print(np.shape(t))\n",
    "start_time = TIME.time()\n",
    "u,net_time=Modelrun(x0,t[1:],model)\n",
    "u_net=u.T[0].flatten()\n",
    "print(\"Shape netpred \",np.shape(u_net))\n",
    "print(\"net time\", net_time)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_net)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "\n",
    "\n",
    "plt.plot(u_ref,\"b\")\n",
    "plt.plot(u_net,\"r\")\n",
    "plt.show()\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab06f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc cuda.cu -o a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9933a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b023de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
